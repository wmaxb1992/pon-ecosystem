# PON Ecosystem - Complete Infrastructure as Code (IaC)
# ================================================================
# This blueprint deploys the ENTIRE PON ecosystem on Render.com:
# - Frontend (Next.js video interface) 
# - Backend (Python/FastAPI video processing)
# - AI Terminal with Grok integration
# - CEO AI Bot (strategic orchestration)
# - Multi-Worker AI System (Celery/Redis)
# - Database and caching layer
# - SSH Terminal access for instant Grok AI
# - Monitoring and logging systems
# ================================================================

version: "1"

services:
  # ===========================================
  # MAIN WEB SERVICE - PON Ecosystem Frontend
  # ===========================================
  - type: web
    name: pon-ecosystem
    runtime: python
    plan: standard  # $25/month for production workloads
    region: ohio     # ohio, oregon, or singapore
    
    # Auto-deploy on GitHub push to main
    autoDeployTrigger: commit  # Modern replacement for autoDeploy: true
    branch: main
    
    # Build the entire ecosystem
    buildCommand: |
      echo "üöÄ Building Complete PON Ecosystem..."
      
      # Install Python dependencies first
      pip install --upgrade pip
      pip install -r requirements_render.txt
      
      # Verify critical imports work
      python -c "import requests, rich, redis, celery; print('‚úÖ Core dependencies installed')"
      
      # Setup environment
      mkdir -p logs videos thumbnails
      chmod +x *.sh
      
      # Install Node.js for frontend (using system package manager)
      curl -fsSL https://deb.nodesource.com/setup_18.x | sudo bash -
      sudo apt-get install -y nodejs
      
      # Build frontend
      if [ -d "frontend" ]; then
        cd frontend
        npm install
        npm run build
        cd ..
        echo "‚úÖ Frontend built successfully"
      else
        echo "‚ö†Ô∏è  Frontend directory not found, skipping"
      fi
      
      # Setup AI system
      python -c "
      import sqlite3
      conn = sqlite3.connect('ai_memory.db')
      conn.execute('CREATE TABLE IF NOT EXISTS memories (id INTEGER PRIMARY KEY, content TEXT, timestamp REAL)')
      conn.close()
      print('‚úÖ AI memory database initialized')
      "
      
      echo "‚úÖ PON Ecosystem build complete!"
    
    # Start the complete ecosystem
    startCommand: |
      echo "üéØ Starting Complete PON Ecosystem..."
      python render_server.py
    
    # Health check endpoint
    healthCheckPath: /health
    
    # Environment variables for the entire system
    envVars:
      # AI Configuration
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: GROK_MODEL
        value: grok-3-fast
      - key: OPENAI_API_KEY
        value: ""  # Optional fallback
      
      # Multi-Provider AI Keys
      - key: OPENROUTER_API_KEY
        value: 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
      - key: OPENROUTER_MODEL
        value: meta-llama/llama-3.1-405b-instruct
      - key: OPENROUTER_FALLBACK_MODEL
        value: anthropic/claude-3.5-sonnet
      
      # System Configuration
      - key: ENVIRONMENT
        value: production
      - key: LOG_LEVEL
        value: INFO
      - key: DEBUG
        value: "false"
      
      # Database URLs
      - key: REDIS_URL
        fromService:
          type: keyvalue
          name: pon-redis
          property: connectionString
      - key: DATABASE_URL
        fromDatabase:
          name: pon-database
          property: connectionString
      
      # Service URLs
      - key: FRONTEND_URL
        value: https://pon-ecosystem.onrender.com
      - key: BACKEND_URL
        value: https://pon-ecosystem.onrender.com/api
      
      # Security
      - key: SECRET_KEY
        generateValue: true
      - key: JWT_SECRET
        generateValue: true
      
      # Feature Flags
      - key: ENABLE_SSH_TERMINAL
        value: "true"
      - key: ENABLE_CEO_AI
        value: "true"
      - key: ENABLE_MULTI_WORKERS
        value: "true"
      - key: ENABLE_MONITORING
        value: "true"
      
      # Resource Limits
      - key: MAX_WORKERS
        value: "4"
      - key: MAX_MEMORY_MB
        value: "1024"
      - key: WORKER_TIMEOUT
        value: "300"

  # =======================================
  # CEO AI BOT - Strategic Orchestration
  # =======================================
  - type: worker
    name: ceo-ai-bot
    runtime: python
    plan: starter
    
    buildCommand: |
      pip install --upgrade pip
      pip install -r requirements_render.txt
      echo "‚úÖ CEO AI Bot ready for strategic command"
    
    startCommand: |
      python ceo_ai_bot.py --mode=production --log-level=INFO
    
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: OPENROUTER_API_KEY
        value: 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
      - key: REDIS_URL
        fromService:
          type: keyvalue
          name: pon-redis
          property: connectionString
      - key: WORKER_TYPE
        value: ceo_orchestrator
      - key: ENVIRONMENT
        value: production

  # =======================================
  # AI MULTI-WORKER SYSTEM
  # =======================================
  
  # Code Generation Worker
  - type: worker
    name: ai-code-worker
    runtime: python
    plan: starter
    
    buildCommand: |
      echo "üì¶ Installing dependencies for Code Worker..."
      pip install --upgrade pip
      pip install -r requirements_render.txt
      
      # Verify Celery and Redis are installed
      python -c "import celery, redis, requests; print('‚úÖ Worker dependencies installed')"
      
      echo "‚úÖ Code Worker build complete!"
    
    startCommand: |
      celery -A ai_multi_worker worker \
        --loglevel=info \
        --queues=code_queue \
        --concurrency=2 \
        --hostname=code_worker@%h \
        --max-tasks-per-child=100
    
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: OPENROUTER_API_KEY
        value: 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
      - key: REDIS_URL
        fromService:
          type: keyvalue
          name: pon-redis
          property: connectionString
      - key: WORKER_TYPE
        value: code_worker
      - key: ENVIRONMENT
        value: production

  # Code Generation Worker - Instance 2
  - type: worker
    name: ai-code-worker-2
    runtime: python
    plan: starter
    
    buildCommand: |
      echo "üì¶ Installing dependencies for Code Worker 2..."
      pip install --upgrade pip
      pip install -r requirements_render.txt
      echo "‚úÖ Code Worker 2 build complete!"
    
    startCommand: |
      celery -A ai_multi_worker worker \
        --loglevel=info \
        --queues=code_queue \
        --concurrency=2 \
        --hostname=code_worker_2@%h \
        --max-tasks-per-child=100
    
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: OPENROUTER_API_KEY
        value: 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
      - key: REDIS_URL
        fromService:
          type: keyvalue
          name: pon-redis
          property: connectionString
      - key: WORKER_TYPE
        value: code_worker
      - key: ENVIRONMENT
        value: production

  # Quality Assurance Worker
  - type: worker
    name: ai-quality-worker
    runtime: python
    plan: starter
    
    buildCommand: |
      echo "üì¶ Installing dependencies for Quality Worker..."
      pip install --upgrade pip
      pip install -r requirements_render.txt
      echo "‚úÖ Quality Worker build complete!"
    
    startCommand: |
      celery -A ai_multi_worker worker \
        --loglevel=info \
        --queues=quality_queue \
        --concurrency=1 \
        --hostname=quality_worker@%h \
        --max-tasks-per-child=50
    
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: OPENROUTER_API_KEY
        value: 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
      - key: REDIS_URL
        fromService:
          type: keyvalue
          name: pon-redis
          property: connectionString
      - key: WORKER_TYPE
        value: quality_worker
      - key: ENVIRONMENT
        value: production

  # Memory Management Worker  
  - type: worker
    name: ai-memory-worker
    runtime: python
    plan: starter
    
    buildCommand: |
      echo "üì¶ Installing dependencies for Memory Worker..."
      pip install --upgrade pip
      pip install -r requirements_render.txt
      echo "‚úÖ Memory Worker build complete!"
    
    startCommand: |
      celery -A ai_multi_worker worker \
        --loglevel=info \
        --queues=memory_queue \
        --concurrency=1 \
        --hostname=memory_worker@%h \
        --max-tasks-per-child=75
    
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: OPENROUTER_API_KEY
        value: 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
      - key: REDIS_URL
        fromService:
          type: keyvalue
          name: pon-redis
          property: connectionString
      - key: WORKER_TYPE
        value: memory_worker
      - key: ENVIRONMENT
        value: production

  # =======================================
  # SSH TERMINAL SERVICE - Instant Grok AI
  # =======================================
  - type: web
    name: instant-grok-terminal
    runtime: python
    plan: starter
    
    buildCommand: |
      echo "üîß Setting up SSH Terminal for instant Grok access..."
      pip install --upgrade pip
      pip install -r requirements_render.txt
      
      # Verify critical imports work
      python -c "import requests, rich; print('‚úÖ Terminal dependencies installed')"
      
      echo "‚úÖ SSH Terminal build complete!"
    
    startCommand: |
      python instant_grok_terminal.py --port=$PORT --production
    
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: TERMINAL_THEME
        value: cyberpunk
      - key: ENABLE_ASCII_ART
        value: "true"
      - key: SSH_ENABLED
        value: "true"

  # =======================================
  # REDIS DATABASE SERVICE
  # =======================================
  - type: keyvalue  # Modern type for Redis/Key-Value instances
    name: pon-redis
    plan: free  # Free plan - 25MB RAM, sufficient for development and small production
    ipAllowList:
      - source: 0.0.0.0/0
        description: "Allow external connections for development"

# =======================================
# DATABASES
# =======================================

databases:
  - name: pon-database
    databaseName: pon_ecosystem
    user: pon_user
    plan: free  # Free plan - 1GB storage, sufficient for development and small production

# =======================================
# ENVIRONMENT GROUPS
# =======================================

envVarGroups:
  - name: ai-common
    envVars:
      - key: GROK_API_KEY
        value: xai-E7Ml5WgMcMYT0lxew2n1b6EwlD8oD3x8OOVuX4OvxSUI9IvLhT2B3ZpESW52N50l2qBNckXyRRkEzv6N
      - key: GROK_MODEL
        value: grok-3-fast
      - key: ENVIRONMENT
        value: production
      - key: LOG_LEVEL
        value: INFO
